{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLIENTS = 9\n",
    "TEST_CLIENT = None\n",
    "\n",
    "DATA_PATH_PATTERN = \"../data/Device #%d.csv\"\n",
    "PRETRAINED_MODEL = \"../models/dl.h5\"\n",
    "\n",
    "WHOLE_CLASSES = ['benign', 'm_scan', 'm_ack', 'm_syn', 'm_udp', 'm_udpplain', 'g_combo', 'g_junk', 'g_scan', 'g_tcp', 'g_udp']\n",
    "BINARY_MODE = False\n",
    "BATCH_SIZE = 64\n",
    "NB_CLASSES = len(WHOLE_CLASSES)\n",
    "NB_EPOCHES = 1\n",
    "NB_ROUNDS = 20\n",
    "MX_RECORDS = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global le, sc\n",
    "sc = load('../models/std_scaler.bin')\n",
    "le = load('../models/lab_encoder.bin')\n",
    "\n",
    "\n",
    "def preprocessor(_client_data: pd.DataFrame):\n",
    "    global sc, le\n",
    "    _client_data = shuffle(_client_data)\n",
    "    _x = _client_data.drop([\"type\"], axis=1)\n",
    "    _y = _client_data[\"type\"]\n",
    "    _x = sc.transform(_x)\n",
    "    \n",
    "    if le is None:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(WHOLE_CLASSES)\n",
    "    \n",
    "    if BINARY_MODE:\n",
    "        _y = (_y == \"benign\").astype(int)\n",
    "    else:\n",
    "        _y = le.transform(_y)\n",
    "        _y = tf.keras.utils.to_categorical(_y, num_classes=NB_CLASSES)\n",
    "        \n",
    "    return _x, _y\n",
    "\n",
    "\n",
    "def make_dataset(_x, _y):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        collections.OrderedDict(\n",
    "            x=tf.constant(_x),\n",
    "            y=tf.constant(_y)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def client_data(_x, _y):\n",
    "    indicies = np.random.randint(len(_x), size=MX_RECORDS)\n",
    "    _client_data = make_dataset(_x[indicies], _y[indicies])\n",
    "    return _client_data.shuffle(MX_RECORDS).batch(BATCH_SIZE).repeat(NB_EPOCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global raw_clients_data, processed_data\n",
    "raw_clients_data = []\n",
    "processed_data = []\n",
    "test_raw_data = None\n",
    "\n",
    "for idx in range(NB_CLIENTS):\n",
    "    raw_content = shuffle(pd.read_csv(DATA_PATH_PATTERN % (idx + 1)))\n",
    "    \n",
    "    if TEST_CLIENT is not None:\n",
    "        if TEST_CLIENT == idx:\n",
    "            test_raw_data = raw_content\n",
    "            continue\n",
    "    else:\n",
    "        train_data, test_data = train_test_split(raw_content, test_size=0.2, random_state=101)\n",
    "\n",
    "        if test_raw_data is None:\n",
    "            test_raw_data = test_data\n",
    "        else:\n",
    "            test_raw_data = pd.concat([test_raw_data, test_data])\n",
    "        raw_content = train_data\n",
    "        \n",
    "    raw_clients_data.append(raw_content)\n",
    "    processed_data.append(preprocessor(raw_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_client_data = [client_data(*data) for data in processed_data]\n",
    "element_spec = train_client_data[0].element_spec\n",
    "\n",
    "test_x, test_y = preprocessor(test_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_dim = 116),\n",
    "        tf.keras.layers.GroupNormalization(),\n",
    "#         tf.keras.layers.BatchNormalization(synchronized=True, input_dim=116),\n",
    "#         tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "        tf.keras.layers.Dense(32),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.05),\n",
    "        tf.keras.layers.Dense(NB_CLASSES, activation = \"softmax\")\n",
    "    ])\n",
    "    model.load_weights(PRETRAINED_MODEL)\n",
    "    return model\n",
    "\n",
    "def model_fn():\n",
    "    model = create_model()\n",
    "    return tff.learning.models.from_keras_model(\n",
    "        model,\n",
    "        input_spec=element_spec,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.CategoricalAccuracy()\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.RMSprop()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = create_model()\n",
    "evaluation.compile(tf.keras.optimizers.RMSprop(), 'binary_crossentropy', metrics=['acc'])\n",
    "pretrained_weights = evaluation.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(nb_rounds=NB_ROUNDS):\n",
    "    state = trainer.initialize()\n",
    "    state = trainer.set_model_weights(state, tff.learning.models.ModelWeights(pretrained_weights, []))\n",
    "    history = []\n",
    "    \n",
    "    for _ in range(nb_rounds):\n",
    "        start_t = time.time()\n",
    "        train_client_data = [client_data(*data) for data in processed_data]\n",
    "        state, metrics = trainer.next(state, train_client_data)\n",
    "        history.append(metrics['client_work']['train'])\n",
    "        train_metrics = metrics['client_work']['train']\n",
    "        end_t = time.time()\n",
    "        print('train metrics {m}, round time {t:.2f} seconds'.format(m=train_metrics, t=(end_t - start_t)))\n",
    "        evaluation.set_weights(trainer.get_model_weights(state).trainable)\n",
    "#         evaluation.evaluate(test_x, test_y)\n",
    "        \n",
    "    return state, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state, history = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.set_weights(trainer.get_model_weights(state).trainable)\n",
    "loss, acc = evaluation.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test Accuracy: { acc }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = evaluation.predict(test_x)\n",
    "roc_matrix = np.zeros((NB_CLASSES, NB_CLASSES))\n",
    "\n",
    "for corr, pred in zip(test_y, pred_y):\n",
    "    corr_idx = np.argmax(corr)\n",
    "    pred_idx = np.argmax(pred)\n",
    "    roc_matrix[pred_idx][corr_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(roc_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
